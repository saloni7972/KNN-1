{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6c395-c44f-49dd-bcbf-f1e7419cc99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf0ff2c0-12b5-4e22-931e-b2f6e4d69e58",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58aaf00-3293-4238-88c2-c4434d7fe41d",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point. While it can be used for either regression or classification problems, it is typically used as a classification algorithm, working off the assumption that similar points can be found near one anothER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981473fb-2b52-4bca-813f-2189dcb8950f",
   "metadata": {},
   "source": [
    "Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26430524-5622-4b78-989c-7c5c18bf86c4",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "The value of k is very crucial in the KNN algorithm to define the number of neighbors in the algorithm. The value of k in the k-nearest neighbors (k-NN) algorithm should be chosen based on the input data. If the input data has more outliers or noise, a higher value of k would be better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7afdfe-7f53-41b3-bb6e-4f75e9d1689e",
   "metadata": {},
   "source": [
    "Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c540c17-1386-43eb-8aee-3c09365936b8",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "Knn Classifier: Predicts a class by using the highest majority category among its k nearest neighbors. Knn Regression: Predicts a value by using the mean of the k nearest neighbors.\n",
    "regression model: codomain of model is a continuous space, e.g. R R classification model: codomain of model is a discrete space, e.g. {0, 1} { 0, 1 }."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66980eb-1962-4f42-b73f-c3bcc956685e",
   "metadata": {},
   "source": [
    "Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c6209b-c275-46fe-ad61-d9db4c0dd0f4",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "All the measures are used with the k-NN classifier individually with three different weights, and these measures are applied with k-NN to the same training and test samples each time. For evaluating the performance of k-NN we have used both accuracy (A) and F-score (F) metric. It should be noted that: 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8344c1-7837-44d2-98aa-05fbbb4ae742",
   "metadata": {},
   "source": [
    "Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b9060-ec17-46cc-8757-81c3c5be9e95",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "The curse of dimensionality has different effects on distances between two points and distances between points and hyperplanes. An animation illustrating the effect on randomly sampled data points in 2D, as a 3rd dimension is added (with random coordinates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfa77a-ccfa-4399-bbae-aad3394c2d1f",
   "metadata": {},
   "source": [
    "Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dda91b-1f94-467b-922b-48dfe02b3b17",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "It can be used for data that are continuous, discrete, ordinal and categorical which makes it particularly useful for dealing with all kind of missing data. The assumption behind using KNN for missing values is that a point value can be approximated by the values of the points that are closest to it, based on other variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe528d-9f2d-442d-9ea5-ddad9a43b182",
   "metadata": {},
   "source": [
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014e421-7696-4da6-80e1-46d8a4a0e86e",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "Knn Classifier: Predicts a class by using the highest majority category among its k nearest neighbors.\n",
    "codomain of model is a discrete space, e.g. {0,1}\n",
    "Knn Regression: Predicts a value by using the mean of the k nearest neighbors.\n",
    "codomain of model is a continuous space, e.g. R\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbed97-7525-4c8c-b93e-b1c7b597db96",
   "metadata": {},
   "source": [
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd029f5f-344c-4a70-bd8f-a88a28b490c3",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "STRENGTH= No Training Period: KNN is called Lazy Learner (Instance based learning). It does not learn anything in the training period. It does not derive any discriminative function from the training data. In other words, there is no training period for it. It stores the training dataset and learns from it only at the time of making real time predictions. This makes the KNN algorithm much faster than other algorithms that require training e.g. SVM, Linear Regression etc.\n",
    "Since the KNN algorithm requires no training before making predictions, new data can be added seamlessly which will not impact the accuracy of the algorithm.\n",
    "\n",
    "WEAKNESS= Does not work well with large dataset: In large datasets, the cost of calculating the distance between the new point and each existing point is huge which degrades the performance of the algorithm.\n",
    " Does not work well with high dimensions: The KNN algorithm doesnâ€™t work well with high dimensional data because with large number of dimensions, it becomes difficult for the algorithm to calculate the distance in each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a173f784-e523-4dc2-8c19-8b39e8945a90",
   "metadata": {},
   "source": [
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabec64-a3d2-4c69-bc1d-538c03a84873",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "Manhattan and Euclidean Distance, two way of measuring distance and performance in deep learning, is explained in simple terms. It is a beginner, basic guide to machine learning distance functions and cost functions. As always our content is beginner friendly.While both are used in regression models, or models with continuous numeric output, unlike classifications, Euclidean seems to be slightly more common. But only experimentation can reveal the better result for the specific scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214999a-182b-4fa8-b8d1-32f124cc305f",
   "metadata": {},
   "source": [
    "Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f0230-956d-4f01-95d0-4dfdf1ccd6a0",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "Feature Scaling is one such process in which we transform the data into a better version. Feature Scaling is done to normalize the features in the dataset into a finite range. I will be discussing why this is required and what are the common feature scaling techniques used. Real-world datasets often contain features that are varying in degrees of magnitude, range, and units. Therefore, in order for machine learning models to interpret these features on the same scale, we need to perform feature scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
